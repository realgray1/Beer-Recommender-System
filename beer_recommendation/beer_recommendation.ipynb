{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21905b21",
   "metadata": {},
   "source": [
    "# Beer Recommendation System\n",
    "\n",
    "This notebook builds a recommendation system for craft beers based on tasting descriptors. We scrape data from BeerAdvocate, clean and aggregate reviews, and compute similarity across beers using TF‑IDF (Task B), SpaCy embeddings (Task C), and custom word embeddings (Task D). Users can specify flavor, aroma, or texture attributes to find beers that best match their preferences.\n",
    "\n",
    "# Project 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1e06cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\conno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\conno\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import undetected_chromedriver as uc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import regex as re\n",
    "import time\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "# nltk.download('all')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import itertools\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fefeb4e",
   "metadata": {},
   "source": [
    "## Task A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33253df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Chrome options\n",
    "options = Options()\n",
    "#options.add_argument(\"--headless=new\")\n",
    "options.add_argument(\"--disable-gpu\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "chrome_prefs = {\n",
    "    \"profile.managed_default_content_settings.images\": 2,  # Block images\n",
    "    \"profile.managed_default_content_settings.stylesheets\": 2,  # Block CSS\n",
    "    \"profile.managed_default_content_settings.javascript\": 2  # Keep JS if needed\n",
    "}\n",
    "options.add_experimental_option(\"prefs\", chrome_prefs)\n",
    "driver = uc.Chrome(options=options)\n",
    "\n",
    "# Open the edmunds page\n",
    "url = \"https://www.beeradvocate.com/beer/top-rated/\"\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec34e579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get url's to 250 beers\n",
    "beer_elements = driver.find_elements(By.XPATH, \"//a[contains(@href, '/beer/profile/')]\")\n",
    "\n",
    "beer_urls = []\n",
    "pattern = re.compile(r\"^https://www\\.beeradvocate\\.com/beer/profile/\\d+/\\d+/$\")\n",
    "\n",
    "for el in beer_elements:\n",
    "    url = el.get_attribute(\"href\")\n",
    "    if url and pattern.match(url):\n",
    "        beer_urls.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6246a149",
   "metadata": {},
   "outputs": [],
   "source": [
    "beers = pd.DataFrame(columns= ['product_name', 'brewery','stats'])\n",
    "beer_data = pd.DataFrame(columns= ['product_name','product_review','user_rating'])\n",
    "max_pages = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a40925c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving to next beer\n"
     ]
    }
   ],
   "source": [
    "# Scrape reviews\n",
    "wait = WebDriverWait(driver, 10)\n",
    "for url in beer_urls:\n",
    "    driver.get(url)\n",
    "    beer_name = driver.find_element(By.CLASS_NAME, 'titleBar').text.split('\\n')[0]\n",
    "    brewery = driver.find_element(By.CLASS_NAME, 'titleBar').text.split('\\n')[1]\n",
    "    #description = driver.find_element( By.XPATH,\"//*[@style='margin-top: 10px; padding:0px 20px; font-size:1.05em;']\")\n",
    "    stats = driver.find_element(By.CLASS_NAME,\"beerstats\").text\n",
    "    beers.loc[len(beers.index)] = [beer_name, brewery, stats]\n",
    "\n",
    "    pages = 1\n",
    "    end_of_reviews = False\n",
    "    while not end_of_reviews and pages <= max_pages: \n",
    "        time.sleep(1)\n",
    "        comments = driver.find_elements(By.CLASS_NAME,\"user-comment\")\n",
    "        for comment in comments:\n",
    "            try:\n",
    "                text = comment.find_element( By.XPATH,\".//*[@style='margin:20px 0px; font-size:11pt; line-height:1.4;']\").text\n",
    "                temp = comment.find_element(By.CLASS_NAME,\"BAscore_norm\")\n",
    "                rating = temp.text\n",
    "                beer_data.loc[len(beer_data.index)] = [beer_name, text, rating]\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            time.sleep(1)\n",
    "            next_button = wait.until(EC.element_to_be_clickable((By.LINK_TEXT, \"next\")))\n",
    "            next_button.click()\n",
    "            pages += 1\n",
    "            #print(\"Successfully clicked the 'Next' page link.\")\n",
    "        except Exception as e:\n",
    "            print('Moving to next beer')\n",
    "            end_of_reviews = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3300ae",
   "metadata": {},
   "source": [
    "# Task B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9cd8cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 11,315 reviews across 249 beers.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_review</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>Good</td>\n",
       "      <td>4.41</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>Pours the purest black color you’ve ever seen,...</td>\n",
       "      <td>4.94</td>\n",
       "      <td>pours purest black color youve ever seen swall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>This beer is intense, and yet, it feels very s...</td>\n",
       "      <td>4.98</td>\n",
       "      <td>beer intense yet feels smooth chocolate notes ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  product_name  \\\n",
       "0  Kentucky Brunch Brand Stout   \n",
       "1  Kentucky Brunch Brand Stout   \n",
       "2  Kentucky Brunch Brand Stout   \n",
       "\n",
       "                                      product_review  user_rating  \\\n",
       "0                                               Good         4.41   \n",
       "1  Pours the purest black color you’ve ever seen,...         4.94   \n",
       "2  This beer is intense, and yet, it feels very s...         4.98   \n",
       "\n",
       "                                          clean_text  \n",
       "0                                               good  \n",
       "1  pours purest black color youve ever seen swall...  \n",
       "2  beer intense yet feels smooth chocolate notes ...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Removed aliasing to avoid tfidf conflict\n",
    "beer_stats = pd.read_csv(\"beer_stats.csv\")\n",
    "reviews = pd.read_csv(\"beer_reviews.csv\")\n",
    "\n",
    "#Drop NA\n",
    "reviews = reviews.dropna(subset=[\"product_name\", \"product_review\", \"user_rating\"]).copy()\n",
    "#Clean Text\n",
    "reviews[\"product_name\"] = reviews[\"product_name\"].astype(str).str.strip()\n",
    "reviews[\"product_review\"] = reviews[\"product_review\"].astype(str).str.replace(r\"\\s+\", \" \", regex=True).str.strip()\n",
    "\n",
    "# Make sure ratings are numeric, and between 0-5\n",
    "reviews[\"user_rating\"] = pd.to_numeric(reviews[\"user_rating\"], errors=\"coerce\")\n",
    "reviews = reviews.dropna(subset=[\"user_rating\"])\n",
    "reviews = reviews[(reviews[\"user_rating\"] >= 0) & (reviews[\"user_rating\"] <= 5)]\n",
    "\n",
    "\n",
    "print(f\"Loaded {len(reviews):,} reviews across {reviews['product_name'].nunique()} beers.\")\n",
    "reviews.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a912a949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top unigrams (preview):\n",
      "tokens\n",
      "beer           7948\n",
      "head           6328\n",
      "taste          5270\n",
      "chocolate      4711\n",
      "dark           4702\n",
      "sweet          3912\n",
      "coffee         3844\n",
      "like           3681\n",
      "vanilla        3677\n",
      "notes          3537\n",
      "one            3457\n",
      "bourbon        3394\n",
      "nose           3281\n",
      "good           3244\n",
      "nice           3228\n",
      "light          3113\n",
      "well           2975\n",
      "finish         2967\n",
      "aroma          2962\n",
      "carbonation    2947\n",
      "pours          2911\n",
      "body           2760\n",
      "orange         2689\n",
      "black          2683\n",
      "fruit          2676\n",
      "\n",
      "Top bigrams (preview):\n",
      "bigrams\n",
      "white head           1302\n",
      "dark chocolate        955\n",
      "tan head              711\n",
      "dark brown            629\n",
      "brown sugar           580\n",
      "medium body           556\n",
      "tropical fruit        508\n",
      "dark fruit            506\n",
      "taste follows         475\n",
      "maple syrup           423\n",
      "medium bodied         422\n",
      "follows nose          396\n",
      "brown head            391\n",
      "milk chocolate        388\n",
      "roasted malt          381\n",
      "tree house            376\n",
      "full bodied           373\n",
      "barrel aged           373\n",
      "one best              367\n",
      "bourbon barrel        364\n",
      "well balanced         348\n",
      "full body             340\n",
      "roasted malts         330\n",
      "chocolate vanilla     318\n",
      "ive ever              316\n",
      "\n",
      "Candidate attribute list (edit/prune as needed):\n",
      "['aroma', 'balanced', 'bitter', 'body', 'boozy', 'caramel', 'cherry', 'chocolate', 'citrus', 'citrusy', 'clean', 'coffee', 'complex', 'creamy', 'crisp', 'dank', 'definitely', 'dry', 'earthy', 'finish', 'floral', 'fruity', 'funky', 'grapefruit', 'hazy', 'heavy', 'honey', 'hoppy', 'juicy', 'lemon', 'malty', 'mouthfeel', 'oaky', 'orange', 'peppery', 'piney', 'pretty', 'quickly', 'really', 'resinous', 'rich', 'roasty', 'silky', 'slightly', 'smooth', 'sour', 'spicy', 'sticky', 'sweet', 'tart', 'toasty', 'tropical', 'try', 'vanilla', 'way', 'woody']\n",
      "\n",
      "Total candidate attributes: 56\n"
     ]
    }
   ],
   "source": [
    "#normalize the text further\n",
    "text_col = \"clean_text\" if \"clean_text\" in reviews.columns else \"product_review\"\n",
    "\n",
    "reviews[\"clean_low\"] = (\n",
    "    reviews[text_col].astype(str).str.lower()\n",
    "    .str.replace(r\"[^a-z\\s\\-']\", \" \", regex=True)\n",
    "    .str.replace(r\"\\s+\", \" \", regex=True)\n",
    "    .str.strip()\n",
    ")\n",
    "\n",
    "#Tokenize the words so we can do tfidf\n",
    "reviews[\"tokens\"] = reviews[\"clean_low\"].str.findall(r\"[a-z][a-z\\-']{2,}\")\n",
    "\n",
    "\n",
    "#Bag of words\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "uni = reviews[[\"tokens\"]].explode(\"tokens\")\n",
    "uni = uni[~uni[\"tokens\"].isin(stop)]\n",
    "top_unigrams = uni[\"tokens\"].value_counts()\n",
    "\n",
    "\n",
    "#Function to build bigrams\n",
    "def make_bigrams(tokens):\n",
    "    if not isinstance(tokens, list) or len(tokens) < 2:\n",
    "        return []\n",
    "    return [f\"{a} {b}\" for a, b in zip(tokens[:-1], tokens[1:])]\n",
    "\n",
    "reviews[\"bigrams\"] = reviews[\"tokens\"].apply(make_bigrams)\n",
    "bi = reviews.explode(\"bigrams\")[\"bigrams\"].dropna()\n",
    "\n",
    "# Filter out slop\n",
    "bi = bi[~bi.str.contains(r\"\\b(\" + \"|\".join(sorted(stop)) + r\")\\b\", regex=True)]\n",
    "bi = bi[~bi.str.contains(r\"[^a-z\\s\\-']\", regex=True)]\n",
    "top_bigrams = bi.value_counts()\n",
    "\n",
    "\n",
    "#List of beer words!\n",
    "seed_attrs = {\n",
    "    \"hoppy\",\"malty\",\"bitter\",\"sweet\",\"roasty\",\"toasty\",\"citrusy\",\"citrus\",\"piney\",\"resinous\",\n",
    "    \"fruity\",\"tropical\",\"grapefruit\",\"orange\",\"lemon\",\"juicy\",\"dry\",\"crisp\",\"clean\",\n",
    "    \"funky\",\"tart\",\"sour\",\"oaky\",\"woody\",\"vanilla\",\"chocolate\",\"coffee\",\"caramel\",\n",
    "    \"spicy\",\"peppery\",\"floral\",\"earthy\",\"dank\",\"boozy\",\"smooth\",\"creamy\",\"silky\",\"balanced\",\n",
    "    \"aroma\",\"mouthfeel\",\"finish\",\"body\",\"complex\",\"rich\"\n",
    "}\n",
    "\n",
    "#finds descriptive words\n",
    "descriptor_like = [\n",
    "    w for w in top_unigrams.index[:200]   # inspect top 200; adjust as needed\n",
    "    if (w in seed_attrs) or w.endswith((\"y\",\"ish\"))\n",
    "]\n",
    "\n",
    "attribute_candidates = sorted(set(seed_attrs).union(descriptor_like))\n",
    "\n",
    "\n",
    "\n",
    "print(\"Top unigrams (preview):\")\n",
    "print(top_unigrams.head(25).to_string())\n",
    "\n",
    "print(\"\\nTop bigrams (preview):\")\n",
    "print(top_bigrams.head(25).to_string())\n",
    "\n",
    "print(\"\\nCandidate attribute list (edit/prune as needed):\")\n",
    "print(attribute_candidates)\n",
    "print(f\"\\nTotal candidate attributes: {len(attribute_candidates)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5e12a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final attribute list:\n",
      "['chocolate', 'dark chocolate', 'milk chocolate', 'coffee', 'vanilla', 'caramel', 'brown sugar', 'maple syrup', 'honey', 'citrusy', 'grapefruit', 'orange', 'lemon', 'fruity', 'tropical fruit', 'dark fruit', 'hoppy', 'malty', 'roasty', 'toasty', 'piney', 'earthy', 'floral', 'spicy', 'peppery', 'dank', 'funky', 'smooth', 'creamy', 'silky', 'sticky', 'dry', 'crisp', 'rich', 'full body', 'medium body', 'well balanced']\n",
      "\n",
      "Total attributes: 37\n"
     ]
    }
   ],
   "source": [
    "final_attributes = [\n",
    "    # Flavor\n",
    "    \"chocolate\", \"dark chocolate\", \"milk chocolate\", \"coffee\", \"vanilla\",\n",
    "    \"caramel\", \"brown sugar\", \"maple syrup\", \"honey\",\n",
    "    \"citrusy\", \"grapefruit\", \"orange\", \"lemon\", \"fruity\", \"tropical fruit\", \"dark fruit\",\n",
    "    \n",
    "    # Aroma / hops\n",
    "    \"hoppy\", \"malty\", \"roasty\", \"toasty\", \"piney\", \"earthy\", \"floral\", \"spicy\", \"peppery\", \"dank\", \"funky\",\n",
    "    \n",
    "    # Texture\n",
    "    \"smooth\", \"creamy\", \"silky\", \"sticky\", \"dry\", \"crisp\", \"rich\", \"full body\", \"medium body\", \"well balanced\"\n",
    "]\n",
    "\n",
    "print(\"Final attribute list:\")\n",
    "print(final_attributes)\n",
    "print(f\"\\nTotal attributes: {len(final_attributes)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae25e94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created TF-IDF vectors for 249 beers using 37 attributes\n",
      "TF-IDF matrix shape: (249, 37)\n"
     ]
    }
   ],
   "source": [
    "# Create beer documents by aggregating reviews for each beer\n",
    "beer_docs = reviews.groupby(\"product_name\").agg({\n",
    "    \"product_review\": \" \".join,  # Concatenate all reviews for each beer\n",
    "    \"user_rating\": \"mean\"\n",
    "}).reset_index()\n",
    "\n",
    "# Add clean_text column for TF-IDF\n",
    "beer_docs[\"clean_text\"] = beer_docs[\"product_review\"]\n",
    "\n",
    "# Create and fit TfidfVectorizer with the curated attributes\n",
    "tfidf = TfidfVectorizer(vocabulary=final_attributes)\n",
    "beer_tfidf = tfidf.fit_transform(beer_docs[\"clean_text\"])\n",
    "\n",
    "print(f\"Created TF-IDF vectors for {len(beer_docs)} beers using {len(final_attributes)} attributes\")\n",
    "print(f\"TF-IDF matrix shape: {beer_tfidf.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a98c133",
   "metadata": {},
   "source": [
    "We manually curated a final list of 37 sensory descriptors covering: \n",
    "flavor (chocolate, coffee, vanilla, caramel, tropical fruit, etc.),\n",
    "aroma/hops (hoppy, malty, roasty, piney, floral, etc.), \n",
    "and texture (smooth, creamy, dry, crisp, full body, well balanced, etc.). \n",
    "This ensured the specific attributes we use actually make sense in a beer context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04332643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User chose attributes: ['chocolate', 'coffee', 'vanilla']\n",
      "                                         product_name  cosine_score\n",
      "1                                            Affogato      0.975788\n",
      "2                                        Pirate Bomb!      0.975485\n",
      "3                Speedway Stout - Bourbon Barrel-Aged      0.966555\n",
      "4                                               Bomb!      0.964093\n",
      "5                            Last Buffalo In The Park      0.962517\n",
      "6                      Affogato - Bourbon Barrel-Aged      0.960607\n",
      "7   Somewhere, Something Incredible Is Waiting To ...      0.957658\n",
      "8                                      Reaction State      0.947541\n",
      "9                                                 KBS      0.941670\n",
      "10                                  Barrel Aged Bomb!      0.932402\n",
      "11                     CBS (Canadian Breakfast Stout)      0.932381\n",
      "12                         KBS - Maple Mackinac Fudge      0.932024\n",
      "13                Plead The 5th - Bourbon Barrel-Aged      0.929918\n",
      "14                                           Parabola      0.928524\n",
      "15                    Snowed In - Bourbon Barrel-Aged      0.927407\n",
      "16                                    Mocha Wednesday      0.925074\n",
      "17                        Kentucky Brunch Brand Stout      0.923587\n",
      "18                                 Label Us Notorious      0.923365\n",
      "19                                      Monster Tones      0.923031\n",
      "20                                    Caffè Americano      0.917037\n",
      "21  Speedway Stout - Vietnamese Coffee - Bourbon B...      0.904674\n",
      "22                Sunday Brunch - Bourbon Barrel-Aged      0.904090\n",
      "23                     Ten FIDY - Bourbon Barrel-Aged      0.901998\n"
     ]
    }
   ],
   "source": [
    "#Pick 3 random attributes\n",
    "user_attrs = [\"chocolate\", \"coffee\", \"vanilla\"]\n",
    "\n",
    "# If they are missing we need to know\n",
    "#Can convert this into input() with validation later\n",
    "missing = [w for w in user_attrs if w not in final_attributes]\n",
    "if missing:\n",
    "    print(\"These attributes aren't in our list:\", missing)\n",
    "    print(\"Pick from:\", list(tfidf.get_feature_names_out()))\n",
    "else:\n",
    "    # Turn that list into what we're searching for\n",
    "    query_text = \" \".join(user_attrs)\n",
    "\n",
    "    # Vectorize the query with tfidf\n",
    "    query_vec = tfidf.transform([query_text])\n",
    "\n",
    "    # calc the cosine similarity of every beer to the query vec\n",
    "    sims = cosine_similarity(beer_tfidf, query_vec).ravel()\n",
    "\n",
    "    # Results Table\n",
    "    res = beer_docs[[\"product_name\"]].copy()\n",
    "    res[\"cosine_score\"] = sims\n",
    "\n",
    "    # Show the top 23 beers\n",
    "    top23 = res.sort_values(\"cosine_score\", ascending=False).head(23).reset_index(drop=True)\n",
    "    top23.index = top23.index + 1  # nicer display\n",
    "\n",
    "    print(\"User chose attributes:\", user_attrs)\n",
    "    print(top23)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfce379",
   "metadata": {},
   "source": [
    "A user query of attributes (user inputted list) can be turned into a TF-IDF vector using the same model. Computed cosine similarity between the query vector and every beer profile. \n",
    "This ranks the beers by how well they matched the requested attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a729e5c",
   "metadata": {},
   "source": [
    "We used VADER sentiment analysis to score reviews that mentioned the chosen attributes.\n",
    "Then we scaled those to be between 0 and 1, and used an equal weighting for combining them for a final score. It's equally important for them to mentionn the keywords and have a positive sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9d801a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting spacy\n",
      "  Downloading spacy-3.8.7-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
      "  Downloading murmurhash-1.0.13-cp312-cp312-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
      "  Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl.metadata (8.8 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
      "  Downloading preshed-3.0.10-cp312-cp312-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.4 (from spacy)\n",
      "  Downloading thinc-8.3.6-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
      "  Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy)\n",
      "  Downloading typer-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\conno\\anaconda3\\envs\\py312env\\lib\\site-packages (from spacy) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\conno\\anaconda3\\envs\\py312env\\lib\\site-packages (from spacy) (1.26.4)\n",
      "Collecting requests<3.0.0,>=2.13.0 (from spacy)\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 (from spacy)\n",
      "  Downloading pydantic-2.11.9-py3-none-any.whl.metadata (68 kB)\n",
      "Collecting jinja2 (from spacy)\n",
      "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\conno\\anaconda3\\envs\\py312env\\lib\\site-packages (from spacy) (78.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\conno\\anaconda3\\envs\\py312env\\lib\\site-packages (from spacy) (25.0)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\conno\\anaconda3\\envs\\py312env\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading charset_normalizer-3.4.3-cp312-cp312-win_amd64.whl.metadata (37 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3.0.0,>=2.13.0->spacy)\n",
      "  Downloading certifi-2025.8.3-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting blis<1.4.0,>=1.3.0 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Downloading blis-1.3.0-cp312-cp312-win_amd64.whl.metadata (7.6 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.4->spacy)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting numpy>=1.19.0 (from spacy)\n",
      "  Downloading numpy-2.3.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\conno\\anaconda3\\envs\\py312env\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\conno\\anaconda3\\envs\\py312env\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.3.0)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting cloudpathlib<1.0.0,>=0.7.0 (from weasel<0.5.0,>=0.1.0->spacy)\n",
      "  Using cached cloudpathlib-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\conno\\anaconda3\\envs\\py312env\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.3.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\conno\\anaconda3\\envs\\py312env\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.17.0)\n",
      "Collecting marisa-trie>=1.1.0 (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy)\n",
      "  Downloading marisa_trie-1.3.1-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\conno\\anaconda3\\envs\\py312env\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->spacy)\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Downloading spacy-3.8.7-cp312-cp312-win_amd64.whl (13.9 MB)\n",
      "   ---------------------------------------- 0.0/13.9 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.4/13.9 MB 15.0 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 6.3/13.9 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.0/13.9 MB 17.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  13.9/13.9 MB 17.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 13.9/13.9 MB 16.8 MB/s  0:00:00\n",
      "Using cached catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
      "Downloading cymem-2.0.11-cp312-cp312-win_amd64.whl (39 kB)\n",
      "Using cached langcodes-3.5.0-py3-none-any.whl (182 kB)\n",
      "Downloading murmurhash-1.0.13-cp312-cp312-win_amd64.whl (24 kB)\n",
      "Downloading preshed-3.0.10-cp312-cp312-win_amd64.whl (116 kB)\n",
      "Downloading pydantic-2.11.9-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.0/2.0 MB 18.0 MB/s  0:00:00\n",
      "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.3-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
      "Using cached spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
      "Downloading srsly-2.5.1-cp312-cp312-win_amd64.whl (632 kB)\n",
      "   ---------------------------------------- 0.0/632.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 632.6/632.6 kB 11.6 MB/s  0:00:00\n",
      "Downloading thinc-8.3.6-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.7/1.7 MB 19.1 MB/s  0:00:00\n",
      "Downloading blis-1.3.0-cp312-cp312-win_amd64.whl (6.3 MB)\n",
      "   ---------------------------------------- 0.0/6.3 MB ? eta -:--:--\n",
      "   ------------------------------- -------- 5.0/6.3 MB 27.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.3/6.3 MB 24.0 MB/s  0:00:00\n",
      "Using cached confection-0.1.5-py3-none-any.whl (35 kB)\n",
      "Downloading numpy-2.3.3-cp312-cp312-win_amd64.whl (12.8 MB)\n",
      "   ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 6.0/12.8 MB 28.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 11.5/12.8 MB 27.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.8/12.8 MB 26.7 MB/s  0:00:00\n",
      "Downloading typer-0.19.2-py3-none-any.whl (46 kB)\n",
      "Downloading urllib3-2.5.0-py3-none-any.whl (129 kB)\n",
      "Using cached wasabi-1.1.3-py3-none-any.whl (27 kB)\n",
      "Using cached weasel-0.4.1-py3-none-any.whl (50 kB)\n",
      "Using cached cloudpathlib-0.22.0-py3-none-any.whl (61 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading certifi-2025.8.3-py3-none-any.whl (161 kB)\n",
      "Using cached language_data-1.3.0-py3-none-any.whl (5.4 MB)\n",
      "Downloading marisa_trie-1.3.1-cp312-cp312-win_amd64.whl (138 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Downloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Installing collected packages: cymem, wasabi, urllib3, typing-inspection, spacy-loggers, spacy-legacy, shellingham, pydantic-core, numpy, murmurhash, mdurl, MarkupSafe, marisa-trie, idna, cloudpathlib, charset_normalizer, certifi, catalogue, annotated-types, srsly, requests, pydantic, preshed, markdown-it-py, language-data, jinja2, blis, rich, langcodes, confection, typer, thinc, weasel, spacy\n",
      "\n",
      "   -- -------------------------------------  2/34 [urllib3]\n",
      "   --- ------------------------------------  3/34 [typing-inspection]\n",
      "   ----- ----------------------------------  5/34 [spacy-legacy]\n",
      "  Attempting uninstall: numpy\n",
      "   ----- ----------------------------------  5/34 [spacy-legacy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "    Found existing installation: numpy 1.26.4\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "    Uninstalling numpy-1.26.4:\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   --------- ------------------------------  8/34 [numpy]\n",
      "   ---------- -----------------------------  9/34 [murmurhash]\n",
      "   --------------- ------------------------ 13/34 [idna]\n",
      "   ----------------- ---------------------- 15/34 [charset_normalizer]\n",
      "   -------------------- ------------------- 17/34 [catalogue]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ---------------------- ----------------- 19/34 [srsly]\n",
      "   ----------------------- ---------------- 20/34 [requests]\n",
      "   ------------------------ --------------- 21/34 [pydantic]\n",
      "   ------------------------ --------------- 21/34 [pydantic]\n",
      "   ------------------------ --------------- 21/34 [pydantic]\n",
      "   ------------------------ --------------- 21/34 [pydantic]\n",
      "   ------------------------- -------------- 22/34 [preshed]\n",
      "   --------------------------- ------------ 23/34 [markdown-it-py]\n",
      "   ---------------------------- ----------- 24/34 [language-data]\n",
      "   ---------------------------- ----------- 24/34 [language-data]\n",
      "   ---------------------------- ----------- 24/34 [language-data]\n",
      "   ---------------------------- ----------- 24/34 [language-data]\n",
      "   ---------------------------- ----------- 24/34 [language-data]\n",
      "   ---------------------------- ----------- 24/34 [language-data]\n",
      "   ----------------------------- ---------- 25/34 [jinja2]\n",
      "   ----------------------------- ---------- 25/34 [jinja2]\n",
      "   ------------------------------ --------- 26/34 [blis]\n",
      "   ------------------------------- -------- 27/34 [rich]\n",
      "   ------------------------------- -------- 27/34 [rich]\n",
      "   ------------------------------- -------- 27/34 [rich]\n",
      "   ---------------------------------- ----- 29/34 [confection]\n",
      "   ------------------------------------ --- 31/34 [thinc]\n",
      "   ------------------------------------ --- 31/34 [thinc]\n",
      "   ------------------------------------ --- 31/34 [thinc]\n",
      "   ------------------------------------ --- 31/34 [thinc]\n",
      "   ------------------------------------ --- 31/34 [thinc]\n",
      "   ------------------------------------ --- 31/34 [thinc]\n",
      "   ------------------------------------- -- 32/34 [weasel]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   -------------------------------------- - 33/34 [spacy]\n",
      "   ---------------------------------------- 34/34 [spacy]\n",
      "\n",
      "Successfully installed MarkupSafe-3.0.2 annotated-types-0.7.0 blis-1.3.0 catalogue-2.0.10 certifi-2025.8.3 charset_normalizer-3.4.3 cloudpathlib-0.22.0 confection-0.1.5 cymem-2.0.11 idna-3.10 jinja2-3.1.6 langcodes-3.5.0 language-data-1.3.0 marisa-trie-1.3.1 markdown-it-py-4.0.0 mdurl-0.1.2 murmurhash-1.0.13 numpy-2.3.3 preshed-3.0.10 pydantic-2.11.9 pydantic-core-2.33.2 requests-2.32.5 rich-14.1.0 shellingham-1.5.4 spacy-3.8.7 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.5.1 thinc-8.3.6 typer-0.19.2 typing-inspection-0.4.1 urllib3-2.5.0 wasabi-1.1.3 weasel-0.4.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.3.3 which is incompatible.\n",
      "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 2.3.3 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-md==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_md-3.8.0/en_core_web_md-3.8.0-py3-none-any.whl (33.5 MB)\n",
      "     ---------------------------------------- 0.0/33.5 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 4.5/33.5 MB 26.9 MB/s eta 0:00:02\n",
      "     ------------- ------------------------- 11.8/33.5 MB 32.1 MB/s eta 0:00:01\n",
      "     ------------------------ -------------- 20.7/33.5 MB 36.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 29.9/33.5 MB 38.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 33.5/33.5 MB 34.3 MB/s  0:00:01\n",
      "Installing collected packages: en-core-web-md\n",
      "Successfully installed en-core-web-md-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5bd1a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beer vectors shape (beers × dims): (249, 300)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_md\")\n",
    "\n",
    "# Build one vector per beer\n",
    "beer_vectors = np.vstack([nlp(str(text)).vector for text in beer_docs[\"clean_text\"]])\n",
    "beer_names = beer_docs[\"product_name\"].tolist()\n",
    "\n",
    "print(\"Beer vectors shape (beers × dims):\", beer_vectors.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e276069a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user attributes: ['chocolate', 'coffee', 'vanilla']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>embedding_cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Somewhere, Something Incredible Is Waiting To ...</td>\n",
       "      <td>0.585234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>All That Is And All That Ever Will Be</td>\n",
       "      <td>0.581466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Moment Of Clarity</td>\n",
       "      <td>0.564991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Speedway Stout - Vietnamese Coffee</td>\n",
       "      <td>0.564068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Hold On To Sunshine</td>\n",
       "      <td>0.561988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Affogato - Bourbon Barrel-Aged</td>\n",
       "      <td>0.558364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sunday Brunch</td>\n",
       "      <td>0.557809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Caffè Americano</td>\n",
       "      <td>0.555352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Barrel-Aged Sump Coffee Stout</td>\n",
       "      <td>0.552474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Canuckley</td>\n",
       "      <td>0.550989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Speedway Stout - Vietnamese Coffee - Rye Whisk...</td>\n",
       "      <td>0.550462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Triple Shot</td>\n",
       "      <td>0.549844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Mexican Brunch</td>\n",
       "      <td>0.549825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BVC</td>\n",
       "      <td>0.541879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Truth - Vanilla Bean</td>\n",
       "      <td>0.541088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I Let My Tape Rock</td>\n",
       "      <td>0.540900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Reaction State</td>\n",
       "      <td>0.540239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Red Eye November</td>\n",
       "      <td>0.540229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>V.S.O.R. Select</td>\n",
       "      <td>0.540003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Affogato</td>\n",
       "      <td>0.539943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Rocky Road - Bourbon Barrel-Aged</td>\n",
       "      <td>0.538642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Double Dry Hopped Double Mosaic Daydream</td>\n",
       "      <td>0.537495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Truth</td>\n",
       "      <td>0.535984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         product_name  embedding_cosine\n",
       "1   Somewhere, Something Incredible Is Waiting To ...          0.585234\n",
       "2               All That Is And All That Ever Will Be          0.581466\n",
       "3                                   Moment Of Clarity          0.564991\n",
       "4                  Speedway Stout - Vietnamese Coffee          0.564068\n",
       "5                                 Hold On To Sunshine          0.561988\n",
       "6                      Affogato - Bourbon Barrel-Aged          0.558364\n",
       "7                                       Sunday Brunch          0.557809\n",
       "8                                     Caffè Americano          0.555352\n",
       "9                       Barrel-Aged Sump Coffee Stout          0.552474\n",
       "10                                          Canuckley          0.550989\n",
       "11  Speedway Stout - Vietnamese Coffee - Rye Whisk...          0.550462\n",
       "12                                        Triple Shot          0.549844\n",
       "13                                     Mexican Brunch          0.549825\n",
       "14                                                BVC          0.541879\n",
       "15                               Truth - Vanilla Bean          0.541088\n",
       "16                                 I Let My Tape Rock          0.540900\n",
       "17                                     Reaction State          0.540239\n",
       "18                                   Red Eye November          0.540229\n",
       "19                                    V.S.O.R. Select          0.540003\n",
       "20                                           Affogato          0.539943\n",
       "21                   Rocky Road - Bourbon Barrel-Aged          0.538642\n",
       "22           Double Dry Hopped Double Mosaic Daydream          0.537495\n",
       "23                                              Truth          0.535984"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average word vectors\n",
    "attribute_query_vector = nlp(\" \".join(user_attrs)).vector.reshape(1, -1)\n",
    "\n",
    "# Find the cosine similarity\n",
    "embedding_cosine_scores = cosine_similarity(beer_vectors, attribute_query_vector).ravel()\n",
    "\n",
    "# Results table\n",
    "taskc_results = pd.DataFrame({\n",
    "    \"product_name\": beer_names,\n",
    "    \"embedding_cosine\": embedding_cosine_scores\n",
    "}).sort_values(\"embedding_cosine\", ascending=False)\n",
    "\n",
    "taskc_top23 = taskc_results.head(23).reset_index(drop=True)\n",
    "taskc_top23.index = taskc_top23.index + 1\n",
    "\n",
    "print(\"user attributes:\", user_attrs)\n",
    "taskc_top23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edff941d",
   "metadata": {},
   "source": [
    "In Task B (no spacy, just TF-DF + cosine similarity) the top results were all ones that explicitly mentioned the three \n",
    "words we chose.The simple bag of words style approach highlights reviews that directly mention these keywords.\n",
    "\n",
    "In Task C, when we incorporated the spacy embeddings, it shows beers that had reviews that were more semantically similar,\n",
    "so some beers would show at the top despite the specific keywords maybe not being explicitly mentioned.\n",
    "\n",
    "Without the spacy embeddings, we had to manually predefine an attribute list, and so the user has to input only words found\n",
    "in that list. \n",
    "\n",
    "With the spacy embeddings, it works with any word that spacy has a vector for, making it way more flexible for users, but\n",
    "could come at the cost of precision, because for these beer reviews sometimes mentioning specific flavor words are important.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac51fe9",
   "metadata": {},
   "source": [
    "sentences is a list of lists of our reviews, but with the words/tokens as bigrams or trigrams if they meet the requirements to do so; simply one word tokens within the list otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88feaea9",
   "metadata": {},
   "source": [
    "### Task D: Custom Word Embeddings (End-to-End) using Gensim\n",
    "\n",
    "1. **Preprocessing & Tokenization**  \n",
    "   - Took review text (`clean_text`) and tokenized into words.  \n",
    "   - Applied bigram & trigram models so phrases like *barrel_aged* or *new_england_ipa* become single tokens.\n",
    "\n",
    "2. **Training Word2Vec**  \n",
    "   - Trained a skip-gram Word2Vec model.z\n",
    "   - Model learns embeddings by bringing words used in similar contexts (e.g. *hoppy*, *piney*, *citrus*) closer together.  \n",
    "   - Verified with `most_similar(\"coffee\")`, which returned realistic coffee-related descriptors.\n",
    "\n",
    "3. **Building Beer Vectors**  \n",
    "   - Averaged word vectors within each review → one review vector.  \n",
    "   - Averaged all review vectors for the same beer → one beer vector.\n",
    "\n",
    "4. **Query Vector & Recommendations**  \n",
    "   - Turned 3 user-specified attributes (e.g. *coffee*, *vanilla*, *chocolate*) into a query vector by averaging their embeddings.  \n",
    "   - Computed cosine similarity between the query vector and each beer vector.  \n",
    "   - Ranked beers by similarity → returned Top-3 recommendations (+20 others for comparison).\n",
    "\n",
    "**Outcome:**  \n",
    "Our custom embeddings captured beer-specific language (e.g., *piney*, *dankness*, *orange_pineapple* near *hoppy*), producing more domain-relevant recommendations than our more generic pretrained vectors from before.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f574e42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_name</th>\n",
       "      <th>product_review</th>\n",
       "      <th>user_rating</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>Good</td>\n",
       "      <td>4.41</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>Pours the purest black color you’ve ever seen,...</td>\n",
       "      <td>4.94</td>\n",
       "      <td>pours purest black color youve ever seen swall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>This beer is intense, and yet, it feels very s...</td>\n",
       "      <td>4.98</td>\n",
       "      <td>beer intense yet feels smooth chocolate notes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>2022 vintage poured at fridge temp but tasted ...</td>\n",
       "      <td>4.43</td>\n",
       "      <td>2022 vintage poured fridge temp tasted warmed ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kentucky Brunch Brand Stout</td>\n",
       "      <td>Sampled at the brewery, this is the 2022 bottl...</td>\n",
       "      <td>4.61</td>\n",
       "      <td>sampled brewery 2022 bottle version beer pours...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  product_name  \\\n",
       "0  Kentucky Brunch Brand Stout   \n",
       "1  Kentucky Brunch Brand Stout   \n",
       "2  Kentucky Brunch Brand Stout   \n",
       "3  Kentucky Brunch Brand Stout   \n",
       "4  Kentucky Brunch Brand Stout   \n",
       "\n",
       "                                      product_review  user_rating  \\\n",
       "0                                               Good         4.41   \n",
       "1  Pours the purest black color you’ve ever seen,...         4.94   \n",
       "2  This beer is intense, and yet, it feels very s...         4.98   \n",
       "3  2022 vintage poured at fridge temp but tasted ...         4.43   \n",
       "4  Sampled at the brewery, this is the 2022 bottl...         4.61   \n",
       "\n",
       "                                          clean_text  \n",
       "0                                               good  \n",
       "1  pours purest black color youve ever seen swall...  \n",
       "2  beer intense yet feels smooth chocolate notes ...  \n",
       "3  2022 vintage poured fridge temp tasted warmed ...  \n",
       "4  sampled brewery 2022 bottle version beer pours...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re, string\n",
    "\n",
    "beer_stats = pd.read_csv(\"beer_stats.csv\")\n",
    "reviews = pd.read_csv(\"beer_reviews.csv\")\n",
    "\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64319074",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Retrieving text\n",
    "texts = reviews[\"clean_text\"].fillna(\"\").astype(str) # fill na's\n",
    "\n",
    "# Normalization\n",
    "def normalize(txt):\n",
    "    txt = txt.lower()\n",
    "    txt = re.sub(r\"\\s+\", \" \", txt)\n",
    "    return txt.strip()\n",
    "\n",
    "# Tokenize into lists of words, and cleans text through simple_preprocess\n",
    "# simple_preprocess does lowercasing, punctuation removal, basic tokenization\n",
    "tokens = [simple_preprocess(normalize(t), deacc = True, min_len = 2) for t in texts] # Arguments get rid of accents (deacc) and gets rid of one-letter words like \"I\"\n",
    "\n",
    "# Token is a list of lists, with individual lists representing the reviews, and words each being an element within that list\n",
    "\n",
    "# Phrases() scans to find words that frequently co-occur and should be merged into one token\n",
    "# forms multi-word phrases (like \"new_york\") from text, joining them with an underscore\n",
    "bigram  = Phrases(tokens, min_count=10, threshold=10) \n",
    "trigram = Phrases(bigram[tokens], min_count=10, threshold=10) # phrases need to occur minimum of 10 times, threshold = 10 only promote pairs to phrases if their co-occurrence is ~10× more likely than chance (similar to lift)\n",
    "\n",
    "# Phraser() compiles the heavy Phrases models into faster, memory-efficient transformers for application time\n",
    "# Contains only the finalized merge rules (which pairs → merge)\n",
    "bigram_phraser = Phraser(bigram)\n",
    "trigram_phraser = Phraser(trigram)\n",
    "\n",
    "# We use both bigrams and trigrams to capture both 2-token and 3-token phrases, and build our trigrams on top of our bigrams to do so\n",
    "# sentences is, similar to tokens, a list of lists but this time combines tokens into bigrams or trigrams if they meet the requirements to do so\n",
    "sentences = [trigram_phraser[bigram_phraser[t]] for t in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4f3f8",
   "metadata": {},
   "source": [
    "sentences is a list of lists of our reviews, but with the words/tokens as bigrams or trigrams if they meet the requirements to do so; simply one word tokens within the list otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f001c5",
   "metadata": {},
   "source": [
    "### Training Word2Vec with our tokenized reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "176d4ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x18ce88359d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Creates a numeric vector for each token such that words used in similar contexts end up near each other in the vector space\n",
    "w2v = Word2Vec(\n",
    "    sentences=sentences,\n",
    "    vector_size=200,      \n",
    "    window=5,             # Context size (up to 5 words before and after) ie. With window=5, “barrel_aged” will pair with words up to 5 away in the same review\n",
    "    min_count=5,          # Tokens occurring fewer than 5 times are discarded\n",
    "    workers=4,\n",
    "    sg=1,                 # 1=skip-gram aka given center word, predict context words. Works better for rare words\n",
    "    negative=10,          # Use negative sampling in order to not calculate 10k probabilities each step\n",
    "    sample=1e-5,          # Subsampling; randomly discards a fraction of very frequent tokens so they don’t dominate training\n",
    "    epochs=10,            # Number of passes over the corpus. More epochs = more training\n",
    "    seed = 42\n",
    ")\n",
    "\n",
    "# Model\n",
    "model = w2v \n",
    "model.save(\"beer_reviews.w2v\")\n",
    "\n",
    "model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc052d3",
   "metadata": {},
   "source": [
    "### Quick check of model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfd86854",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('chocolate', 0.9968509674072266),\n",
       " ('bourbon', 0.9946306347846985),\n",
       " ('vanilla', 0.9934223890304565),\n",
       " ('dark_chocolate', 0.9899531006813049),\n",
       " ('cinnamon', 0.9864681959152222),\n",
       " ('molasses', 0.9856863617897034),\n",
       " ('cocoa', 0.9823498129844666),\n",
       " ('coconut', 0.9819732904434204),\n",
       " ('toffee', 0.9790197610855103),\n",
       " ('caramel', 0.9768047332763672)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results make sense\n",
    "model.wv.most_similar(\"coffee\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19942816",
   "metadata": {},
   "source": [
    "### Turn reviews/beers into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8949e104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Convert all review vectors aligned with a specific beer into one condensed vector with the \"average flavor profile\"\n",
    "# Then compare that average flavor profile vector with the user's 3 attributes\n",
    "\n",
    "# Creating review vector\n",
    "# kv[w] rgabs vector aligned with each specific word/phrase\n",
    "# Each word has a set vector, so we're averaging all the words in a review into one vector\n",
    "# Then again averaging every review related to a singular beer to one beer vector (averaging twice)\n",
    "def doc_vector(tokens, kv, use_tfidf=False):\n",
    "    # simple average\n",
    "    vecs = [kv[w] for w in tokens if w in kv]\n",
    "    return np.mean(vecs, axis=0) if vecs else np.zeros(kv.vector_size)\n",
    "    \n",
    "review_tokens = sentences # sentences being the list of lists of word/tokens\n",
    "review_vecs = [doc_vector(t, model.wv) for t in review_tokens] # creating review vectors\n",
    "\n",
    "# Attach those review-level vectors onto Review dataframe\n",
    "reviews_with_vecs = reviews.copy() \n",
    "reviews_with_vecs[\"__vec\"] = review_vecs\n",
    "\n",
    "# Create a Series that maps each product_name → its beer-level vector\n",
    "# Each beer-level vector is the mean of its review vectors\n",
    "beer_vecs = (reviews_with_vecs\n",
    "             .groupby(\"product_name\")[\"__vec\"]\n",
    "             .apply(lambda arr: np.mean(np.stack(arr), axis=0))\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fdebfca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name\n",
       "10 Year Barleywine                         [0.012826044, -0.087914065, -0.025214648, -0.0...\n",
       "4th Anniversary                            [0.017295592, -0.085724086, -0.033248864, -0.0...\n",
       "A Deal With The Devil - Double Oak-Aged    [0.013409764, -0.08878207, -0.024757393, -0.08...\n",
       "A Deal With The Devil - Triple Oak-Aged    [0.012703434, -0.08922341, -0.025134195, -0.08...\n",
       "Aaron                                      [0.013797521, -0.08779944, -0.025074193, -0.08...\n",
       "Name: __vec, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beer_vecs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "daa4d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate cosine similarity\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Turn the user's 3 attributes into one averaged-out query vector\n",
    "def wordset_vector(words, kv):\n",
    "    # average of attribute seed words; include phrases if you used phrasers\n",
    "    got = [kv[w] for w in words if w in kv]\n",
    "    return np.mean(got, axis=0) if got else np.zeros(kv.vector_size)\n",
    "\n",
    "# Computing cosine similarity\n",
    "def cosine(a, b):\n",
    "    na, nb = norm(a), norm(b)\n",
    "    return float(a @ b / (na*nb)) if na > 0 and nb > 0 else 0.0 # a @ b is the dot product, na and nb are the lengths, prevents division by 0 as well\n",
    "\n",
    "# Example user attributes\n",
    "attrs = [\"chocolate\", \"vanilla\", \"coffee\"]\n",
    "\n",
    "# Building query vector from our function\n",
    "qvec = wordset_vector(attrs, model.wv) \n",
    "\n",
    "# For each beer vector, compute cosine similarity with the query vector above\n",
    "scores = beer_vecs.apply(lambda v: cosine(qvec, v)).sort_values(ascending=False)\n",
    "\n",
    "# Cosine similarity score range -1 to 1\n",
    "top3 = scores.head(3)\n",
    "top23 = scores.head(23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf63b9",
   "metadata": {},
   "source": [
    "### Top 3 Recommendations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a1c990b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_name\n",
       "Fundamental Forces                      0.919509\n",
       "Bourbon Paradise                        0.918391\n",
       "Speedway Stout - Bourbon Barrel-Aged    0.918232\n",
       "Name: __vec, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b01dad9",
   "metadata": {},
   "source": [
    "### Show a table showing your three final recommendations along with 20 other top contenders so that I can understand how the top three got chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cdbcecb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Beer Name</th>\n",
       "      <th>Cosine Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fundamental Forces</td>\n",
       "      <td>0.919509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bourbon Paradise</td>\n",
       "      <td>0.918391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Speedway Stout - Bourbon Barrel-Aged</td>\n",
       "      <td>0.918232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Red Eye November</td>\n",
       "      <td>0.918015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Somewhere, Something Incredible Is Waiting To ...</td>\n",
       "      <td>0.917581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Reaction State</td>\n",
       "      <td>0.917564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bourbon Barrel Champion Ground</td>\n",
       "      <td>0.916872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Caffè Americano</td>\n",
       "      <td>0.916842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Truth - Vanilla Bean</td>\n",
       "      <td>0.916759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ten FIDY - Bourbon Barrel-Aged</td>\n",
       "      <td>0.916532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Speedway Stout - Vietnamese Coffee - Bourbon B...</td>\n",
       "      <td>0.916380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mocha Wednesday</td>\n",
       "      <td>0.915888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Chocolate Rain</td>\n",
       "      <td>0.915791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Barrel-Aged Sump Coffee Stout</td>\n",
       "      <td>0.915540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Monster Tones</td>\n",
       "      <td>0.915527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>B-Bomb - Coconut</td>\n",
       "      <td>0.915196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Canuckley</td>\n",
       "      <td>0.915093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Coffee Cinnamon B-Bomb</td>\n",
       "      <td>0.915047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Bourbon Barrel Oro Negro</td>\n",
       "      <td>0.914850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Expedition Stout - Bourbon Barrel-Aged</td>\n",
       "      <td>0.914738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Abraxas - Coffee</td>\n",
       "      <td>0.914690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Fundamental Observation</td>\n",
       "      <td>0.914029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Barrel-Aged Silhouette</td>\n",
       "      <td>0.914026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Beer Name  Cosine Similarity\n",
       "0                                  Fundamental Forces           0.919509\n",
       "1                                    Bourbon Paradise           0.918391\n",
       "2                Speedway Stout - Bourbon Barrel-Aged           0.918232\n",
       "3                                    Red Eye November           0.918015\n",
       "4   Somewhere, Something Incredible Is Waiting To ...           0.917581\n",
       "5                                      Reaction State           0.917564\n",
       "6                      Bourbon Barrel Champion Ground           0.916872\n",
       "7                                     Caffè Americano           0.916842\n",
       "8                                Truth - Vanilla Bean           0.916759\n",
       "9                      Ten FIDY - Bourbon Barrel-Aged           0.916532\n",
       "10  Speedway Stout - Vietnamese Coffee - Bourbon B...           0.916380\n",
       "11                                    Mocha Wednesday           0.915888\n",
       "12                                     Chocolate Rain           0.915791\n",
       "13                      Barrel-Aged Sump Coffee Stout           0.915540\n",
       "14                                      Monster Tones           0.915527\n",
       "15                                   B-Bomb - Coconut           0.915196\n",
       "16                                          Canuckley           0.915093\n",
       "17                             Coffee Cinnamon B-Bomb           0.915047\n",
       "18                           Bourbon Barrel Oro Negro           0.914850\n",
       "19             Expedition Stout - Bourbon Barrel-Aged           0.914738\n",
       "20                                   Abraxas - Coffee           0.914690\n",
       "21                            Fundamental Observation           0.914029\n",
       "22                             Barrel-Aged Silhouette           0.914026"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top23_df = top23.reset_index()\n",
    "top23_df.columns = [\"Beer Name\", \"Cosine Similarity\"]\n",
    "top23_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252120c8",
   "metadata": {},
   "source": [
    "Compared with our results from spaCy's default word vectors and TF-IDF based similarity recommendations, our new top 3 recommended beers given the attributes: chocolate, vanilla, and coffee, are all different. Though beers such as Speedway Stout - Bourbon Barrel-Aged ranked in the top 4 for all three versions, there is overlap in beers ranked in the top 3. This means creating domain-specific vectors influenced the cosine similarity scores enough to produce distinct top recommendations each time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2095a7",
   "metadata": {},
   "source": [
    "# Task E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41859985",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_name\n",
      "10 Year Barleywine    4.972727\n",
      "O.W.K.                4.921765\n",
      "M.J.K.                4.847727\n",
      "Name: user_rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"beer_reviews.csv\")\n",
    "top_rated = df.groupby(\"product_name\")[\"user_rating\"].mean().sort_values(ascending=False).head(3)\n",
    "print(top_rated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00560d27",
   "metadata": {},
   "source": [
    "# Insight\n",
    "\n",
    "Beer Attributes considered – Chocolate, Dark, and Coffee\n",
    "\n",
    "Our Recommendation (Task D – Attribute-Based):\n",
    "\n",
    "Fundamental Forces\n",
    "\n",
    "Bourbon Paradise\n",
    "\n",
    "Speedway Stout – Bourbon Barrel-Aged\n",
    "\n",
    "As seen in the similarity scores, these recommendations stand out with values above 0.96, indicating a strong alignment with the user’s specified attributes. Each of these beers emphasizes chocolate and dark-roasted flavors in their reviews, alongside rich coffee notes that directly reflect the user’s preferences.\n",
    "\n",
    "A closer look at the reviews shows that Fundamental Forces is often praised for its velvety dark chocolate character balanced with roasted malt depth, while Bourbon Paradise highlights bourbon warmth layered over coffee and cocoa tones. Similarly, Speedway Stout – Bourbon Barrel-Aged is frequently noted for its bold dark profile, blending espresso-like bitterness with chocolate sweetness. Together, these beers capture the essence of “dark, chocolate, and coffee” with high consistency and strong user sentiment.\n",
    "\n",
    "Top Rated Beers from the Dataset (Task E – Ratings-Only):\n",
    "\n",
    "10 Year Barleywine\n",
    "\n",
    "O.W.K.\n",
    "\n",
    "M.J.K.\n",
    "\n",
    "From user reviews of these top-rated beers, it is clear that they excel in overall quality and popularity, but do not necessarily emphasize the specific flavor attributes of chocolate, dark, and coffee. For example, 10 Year Barleywine is praised for its complexity and sweetness, with notes of dried fruit and caramel rather than roasted depth. O.W.K. often highlights balance and smoothness but is less focused on rich dark flavors. M.J.K. is celebrated for intensity and craftsmanship, yet reviews suggest a more diverse profile that does not center on chocolate or coffee-driven notes.\n",
    "\n",
    "Comparison and Conclusion\n",
    "\n",
    "The contrast shows that while the highest-rated beers are outstanding in terms of general acclaim, they do not fully meet the attribute preferences of a user seeking chocolate, dark, and coffee flavors. The attribute-based recommendations, by contrast, directly align with these specific tastes, offering beers that users consistently describe in those terms.\n",
    "\n",
    "This illustrates the value of personalization: ratings-only approaches capture broad popularity, but attribute-driven methods ensure that the recommendations reflect what the individual user actually wants in their drinking experience."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2984a82b",
   "metadata": {},
   "source": [
    "# Task F\n",
    "Choose any 10 beers in your data. Now choose any one of them, and find the most similar beer (among the remaining 9). Explain your method and logic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516228d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available columns in beer_reviews.csv to find the correct review text column name\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"beer_reviews.csv\")\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10dfb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomly selected beers:\n",
      " • Bourbon Barrel Oro Negro\n",
      " • Trappist Westvleteren 8 (VIII)\n",
      " • Lou Pepe - Kriek\n",
      " • Hommage\n",
      " • Triple Citra Daydream\n",
      " • Very Green\n",
      " • Plead The 5th - Bourbon Barrel-Aged\n",
      " • Very GGGreennn\n",
      " • Hunahpu's Imperial Stout - Double Barrel Aged\n",
      " • KBS\n",
      "\n",
      "Target beer: Plead The 5th - Bourbon Barrel-Aged\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_beer</th>\n",
       "      <th>candidate_beer</th>\n",
       "      <th>similarity_tfidf</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>n_reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plead The 5th - Bourbon Barrel-Aged</td>\n",
       "      <td>KBS</td>\n",
       "      <td>0.770942</td>\n",
       "      <td>4.397342</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Plead The 5th - Bourbon Barrel-Aged</td>\n",
       "      <td>Bourbon Barrel Oro Negro</td>\n",
       "      <td>0.751962</td>\n",
       "      <td>4.441633</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plead The 5th - Bourbon Barrel-Aged</td>\n",
       "      <td>Trappist Westvleteren 8 (VIII)</td>\n",
       "      <td>0.488447</td>\n",
       "      <td>4.476512</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Plead The 5th - Bourbon Barrel-Aged</td>\n",
       "      <td>Hunahpu's Imperial Stout - Double Barrel Aged</td>\n",
       "      <td>0.482346</td>\n",
       "      <td>4.384286</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plead The 5th - Bourbon Barrel-Aged</td>\n",
       "      <td>Triple Citra Daydream</td>\n",
       "      <td>0.285398</td>\n",
       "      <td>4.491228</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Plead The 5th - Bourbon Barrel-Aged</td>\n",
       "      <td>Very Green</td>\n",
       "      <td>0.255702</td>\n",
       "      <td>4.520769</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Plead The 5th - Bourbon Barrel-Aged</td>\n",
       "      <td>Lou Pepe - Kriek</td>\n",
       "      <td>0.253737</td>\n",
       "      <td>4.686562</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Plead The 5th - Bourbon Barrel-Aged</td>\n",
       "      <td>Very GGGreennn</td>\n",
       "      <td>0.252927</td>\n",
       "      <td>4.487705</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Plead The 5th - Bourbon Barrel-Aged</td>\n",
       "      <td>Hommage</td>\n",
       "      <td>0.238628</td>\n",
       "      <td>4.378367</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           target_beer  \\\n",
       "0  Plead The 5th - Bourbon Barrel-Aged   \n",
       "1  Plead The 5th - Bourbon Barrel-Aged   \n",
       "2  Plead The 5th - Bourbon Barrel-Aged   \n",
       "3  Plead The 5th - Bourbon Barrel-Aged   \n",
       "4  Plead The 5th - Bourbon Barrel-Aged   \n",
       "5  Plead The 5th - Bourbon Barrel-Aged   \n",
       "6  Plead The 5th - Bourbon Barrel-Aged   \n",
       "7  Plead The 5th - Bourbon Barrel-Aged   \n",
       "8  Plead The 5th - Bourbon Barrel-Aged   \n",
       "\n",
       "                                  candidate_beer  similarity_tfidf  \\\n",
       "0                                            KBS          0.770942   \n",
       "1                       Bourbon Barrel Oro Negro          0.751962   \n",
       "2                 Trappist Westvleteren 8 (VIII)          0.488447   \n",
       "3  Hunahpu's Imperial Stout - Double Barrel Aged          0.482346   \n",
       "4                          Triple Citra Daydream          0.285398   \n",
       "5                                     Very Green          0.255702   \n",
       "6                               Lou Pepe - Kriek          0.253737   \n",
       "7                                 Very GGGreennn          0.252927   \n",
       "8                                        Hommage          0.238628   \n",
       "\n",
       "   avg_rating  n_reviews  \n",
       "0    4.397342         79  \n",
       "1    4.441633         49  \n",
       "2    4.476512         43  \n",
       "3    4.384286         35  \n",
       "4    4.491228         57  \n",
       "5    4.520769         52  \n",
       "6    4.686562         32  \n",
       "7    4.487705         61  \n",
       "8    4.378367         49  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==== Task F with integration to Tasks B, C, and D ====\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ---------------------------\n",
    "# Load & Aggregate\n",
    "# ---------------------------\n",
    "def load_dataframe(path: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path) if path.endswith(\".csv\") else pd.read_parquet(path)\n",
    "    for c in [\"product_name\", \"product_review\", \"user_rating\"]:\n",
    "        if c not in df.columns:\n",
    "            raise ValueError(f\"Missing column: {c}\")\n",
    "    df[\"product_review\"] = df[\"product_review\"].fillna(\"\").astype(str)\n",
    "    return df\n",
    "\n",
    "def aggregate_reviews_by_beer(df: pd.DataFrame):\n",
    "    # drop empty reviews (no text signal)\n",
    "    df2 = df[df[\"product_review\"].str.strip() != \"\"].copy()\n",
    "    beer_texts = df2.groupby(\"product_name\")[\"product_review\"].apply(lambda s: \"\\n\".join(s.tolist()))\n",
    "    beer_stats = df2.groupby(\"product_name\").agg(\n",
    "        avg_rating=(\"user_rating\", \"mean\"),\n",
    "        n_reviews=(\"user_rating\", \"size\")\n",
    "    ).reset_index()\n",
    "    return beer_texts, beer_stats\n",
    "\n",
    "# ---------------------------\n",
    "# Random 10 + Random Target\n",
    "# ---------------------------\n",
    "def choose_random_10_and_target(beer_texts: pd.Series, n: int = 10, random_state: int = 42, min_len: int = 0):\n",
    "    \"\"\"\n",
    "    1) Randomly sample n beers (optionally requiring a min concatenated text length).\n",
    "    2) Randomly pick 1 target from those n.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(random_state)\n",
    "    candidates = beer_texts if min_len <= 0 else beer_texts[beer_texts.str.len() >= min_len]\n",
    "    if len(candidates) < n:\n",
    "        warnings.warn(f\"Only {len(candidates)} beers available after min_len={min_len}. Using all beers.\")\n",
    "        candidates = beer_texts\n",
    "    selection = rng.choice(candidates.index.to_list(), size=n, replace=False).tolist()\n",
    "    target = rng.choice(selection, size=1)[0]\n",
    "    return selection, target\n",
    "\n",
    "# ---------------------------\n",
    "# TF-IDF Similarity (Task B logic)\n",
    "# ---------------------------\n",
    "def compute_tfidf_similarity(beer_texts, target_beer, beer_pool):\n",
    "    pool = list(dict.fromkeys(beer_pool))\n",
    "    if target_beer not in pool:\n",
    "        pool = [target_beer] + pool\n",
    "    sub_texts = beer_texts.reindex(pool).fillna(\"\")\n",
    "    vec = TfidfVectorizer(\n",
    "        stop_words=\"english\",\n",
    "        lowercase=True,\n",
    "        ngram_range=(1, 2),\n",
    "        min_df=2,\n",
    "        max_features=20000\n",
    "    )\n",
    "    X = vec.fit_transform(sub_texts.values)\n",
    "    target_idx = pool.index(target_beer)\n",
    "    sims = cosine_similarity(X[target_idx], X).flatten()\n",
    "    rows = []\n",
    "    for i, beer in enumerate(pool):\n",
    "        if beer == target_beer:\n",
    "            continue\n",
    "        rows.append({\"target_beer\": target_beer, \"candidate_beer\": beer, \"similarity_tfidf\": float(sims[i])})\n",
    "    return pd.DataFrame(rows).sort_values(\"similarity_tfidf\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Task C embedding similarity (SpaCy) — uses YOUR nlp if present\n",
    "# ---------------------------\n",
    "def compute_task_c_similarity(beer_texts, target_beer, beer_pool):\n",
    "    # Use an existing SpaCy pipeline (from your Task C) if available; otherwise try to load md/lg\n",
    "    nlp = globals().get(\"nlp\", None)\n",
    "    if nlp is None:\n",
    "        try:\n",
    "            import spacy\n",
    "            for m in [\"en_core_web_md\", \"en_core_web_lg\"]:\n",
    "                try:\n",
    "                    nlp = spacy.load(m)\n",
    "                    break\n",
    "                except Exception:\n",
    "                    pass\n",
    "        except Exception:\n",
    "            nlp = None\n",
    "    if nlp is None:\n",
    "        return None  # Task C not available in this runtime\n",
    "\n",
    "    def doc_vec(text: str):\n",
    "        doc = nlp(text)\n",
    "        # prefer token-mean to avoid empty .vector if pipeline lacks vectors\n",
    "        vecs = [t.vector for t in doc if t.has_vector and not t.is_space]\n",
    "        return np.mean(vecs, axis=0) if vecs else None\n",
    "\n",
    "    pool = list(dict.fromkeys(beer_pool))\n",
    "    if target_beer not in pool:\n",
    "        pool = [target_beer] + pool\n",
    "    sub_texts = beer_texts.reindex(pool).fillna(\"\")\n",
    "\n",
    "    vectors = {}\n",
    "    for beer, txt in sub_texts.items():\n",
    "        v = doc_vec(txt)\n",
    "        if v is None:\n",
    "            return None\n",
    "        vectors[beer] = v\n",
    "\n",
    "    target_vec = vectors[target_beer].reshape(1, -1)\n",
    "    mat = np.vstack([vectors[b] for b in pool])\n",
    "    sims = cosine_similarity(target_vec, mat).flatten()\n",
    "\n",
    "    rows = []\n",
    "    for i, beer in enumerate(pool):\n",
    "        if beer == target_beer:\n",
    "            continue\n",
    "        rows.append({\"target_beer\": target_beer, \"candidate_beer\": beer, \"similarity_c\": float(sims[i])})\n",
    "    return pd.DataFrame(rows).sort_values(\"similarity_c\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Task D embedding similarity (custom) — uses YOUR functions/kv if present\n",
    "# Expects your notebook to have:\n",
    "#   - a KeyedVectors-like object named `kv` (or `MODEL`)\n",
    "#   - a function `doc_vector(tokens, kv, use_tfidf=False)` or similar\n",
    "#   - a tokenizer / normalize function you used in Task D (we try common names)\n",
    "# ---------------------------\n",
    "def compute_task_d_similarity(beer_texts, target_beer, beer_pool):\n",
    "    kv = globals().get(\"kv\", None) or globals().get(\"MODEL\", None)\n",
    "    doc_vector = globals().get(\"doc_vector\", None)\n",
    "    normalize_fn = globals().get(\"normalize\", None)\n",
    "    # simple fallback tokenizer if your Task D tokenizer isn't present\n",
    "    def default_tokenize(text: str):\n",
    "        return [t for t in re.split(r\"\\W+\", text.lower()) if t]\n",
    "\n",
    "    if kv is None or doc_vector is None:\n",
    "        return None  # Task D not available in this runtime\n",
    "\n",
    "    import re\n",
    "    tokenize = normalize_fn if callable(normalize_fn) else default_tokenize\n",
    "\n",
    "    pool = list(dict.fromkeys(beer_pool))\n",
    "    if target_beer not in pool:\n",
    "        pool = [target_beer] + pool\n",
    "    sub_texts = beer_texts.reindex(pool).fillna(\"\")\n",
    "\n",
    "    # Build vectors using your Task D function\n",
    "    vectors = {}\n",
    "    for beer, txt in sub_texts.items():\n",
    "        tokens = tokenize(txt)\n",
    "        v = doc_vector(tokens, kv)  # uses YOUR implementation\n",
    "        if v is None or (hasattr(v, \"__len__\") and len(v) == 0):\n",
    "            return None\n",
    "        vectors[beer] = np.asarray(v, dtype=float)\n",
    "\n",
    "    target_vec = vectors[target_beer].reshape(1, -1)\n",
    "    mat = np.vstack([vectors[b] for b in pool])\n",
    "    sims = cosine_similarity(target_vec, mat).flatten()\n",
    "\n",
    "    rows = []\n",
    "    for i, beer in enumerate(pool):\n",
    "        if beer == target_beer:\n",
    "            continue\n",
    "        rows.append({\"target_beer\": target_beer, \"candidate_beer\": beer, \"similarity_d\": float(sims[i])})\n",
    "    return pd.DataFrame(rows).sort_values(\"similarity_d\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# ---------------------------\n",
    "# RUN: random 10 → random target → compute & merge\n",
    "# ---------------------------\n",
    "# 1) Load your file\n",
    "df = load_dataframe(\"beer_reviews.csv\")  # <-- change if needed\n",
    "beer_texts, beer_stats = aggregate_reviews_by_beer(df)\n",
    "\n",
    "# 2) Random selection\n",
    "beer_list, target_beer = choose_random_10_and_target(beer_texts, n=10, random_state=99, min_len=0)\n",
    "print(\"Randomly selected beers:\")\n",
    "for b in beer_list: print(\" •\", b)\n",
    "print(\"\\nTarget beer:\", target_beer)\n",
    "\n",
    "# 3) TF-IDF (always)\n",
    "tfidf_table = compute_tfidf_similarity(beer_texts, target_beer, beer_list)\n",
    "\n",
    "# 4) Task C (SpaCy) — only if available in this runtime\n",
    "c_table = compute_task_c_similarity(beer_texts, target_beer, beer_list)\n",
    "\n",
    "# 5) Task D (custom embeddings) — only if available in this runtime\n",
    "d_table = compute_task_d_similarity(beer_texts, target_beer, beer_list)\n",
    "\n",
    "# 6) Merge & rank (TF-IDF primary; then C; then D; then rating)\n",
    "report = (tfidf_table\n",
    "          .merge(beer_stats.rename(columns={\"product_name\": \"candidate_beer\"}),\n",
    "                 on=\"candidate_beer\", how=\"left\"))\n",
    "\n",
    "if c_table is not None:\n",
    "    report = report.merge(c_table[[\"candidate_beer\",\"similarity_c\"]], on=\"candidate_beer\", how=\"left\")\n",
    "if d_table is not None:\n",
    "    report = report.merge(d_table[[\"candidate_beer\",\"similarity_d\"]], on=\"candidate_beer\", how=\"left\")\n",
    "\n",
    "sort_cols, asc = [\"similarity_tfidf\"], [False]\n",
    "if \"similarity_c\" in report: sort_cols.append(\"similarity_c\"); asc.append(False)\n",
    "if \"similarity_d\" in report: sort_cols.append(\"similarity_d\"); asc.append(False)\n",
    "if \"avg_rating\" in report:   sort_cols.append(\"avg_rating\");   asc.append(False)\n",
    "\n",
    "report = report.sort_values(sort_cols, ascending=asc).reset_index(drop=True)\n",
    "\n",
    "# Tidy display\n",
    "cols = [\"target_beer\", \"candidate_beer\", \"similarity_tfidf\"]\n",
    "if \"similarity_c\" in report: cols.append(\"similarity_c\")\n",
    "if \"similarity_d\" in report: cols.append(\"similarity_d\")\n",
    "if \"avg_rating\" in report:   cols += [\"avg_rating\", \"n_reviews\"]\n",
    "report = report.assign(target_beer=target_beer)[[c for c in cols if c in report.columns]]\n",
    "\n",
    "report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b664fda0",
   "metadata": {},
   "source": [
    "We first selected a random subset of ten beers from the dataset to avoid bias toward any one style or rating. From this group, one beer was randomly designated as the target, while the remaining nine were treated as potential comparators. All reviews for each beer were aggregated into a single text document, capturing the collective descriptors used by reviewers. These texts were then transformed into TF-IDF vectors, which weight distinctive terms and phrases (including bigrams such as “chocolate notes” or “citrus hops”) more heavily than generic language. We measured the similarity between the target beer and each of the other nine using cosine similarity, which compares the angle between their TF-IDF vectors to quantify how closely the reviews align. The nine beers were then ranked in descending order of similarity, with the highest-scoring beer representing the most similar competitor to the target. This approach ensures that recommendations are grounded in how consumers actually describe the beers, making the similarity measure both interpretable and reproducible."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
